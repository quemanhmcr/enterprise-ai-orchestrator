# RAG Tool vá»›i Ollama - HÆ°á»›ng dáº«n Setup

## ğŸš€ Ollama - LLM Local Miá»…n PhÃ­

Ollama cho phÃ©p cháº¡y LLM models locally trÃªn mÃ¡y cá»§a báº¡n - **100% miá»…n phÃ­, khÃ´ng cáº§n API key!**

## ğŸ“¥ BÆ°á»›c 1: CÃ i Ä‘áº·t Ollama

### Windows:
1. Download Ollama: https://ollama.com/download/windows
2. Cháº¡y file installer `OllamaSetup.exe`
3. Ollama sáº½ tá»± Ä‘á»™ng cháº¡y á»Ÿ background

### Kiá»ƒm tra cÃ i Ä‘áº·t:
```powershell
ollama --version
```

## ğŸ“¦ BÆ°á»›c 2: Pull Model nhá» gá»n

Chá»n 1 trong cÃ¡c models sau (tá»« nhá» Ä‘áº¿n lá»›n):

```powershell
# Model siÃªu nhá» - 0.5GB (Recommended cho RAM tháº¥p)
ollama pull qwen2.5:0.5b

# Model nhá» - 1.7GB (Recommended)
ollama pull phi3:mini

# Model vá»«a - 1.6GB
ollama pull gemma2:2b

# Model tá»‘t hÆ¡n - 4.7GB
ollama pull qwen2.5:3b
```

### Kiá»ƒm tra models Ä‘Ã£ cÃ i:
```powershell
ollama list
```

## âš™ï¸ BÆ°á»›c 3: Cáº¥u hÃ¬nh Environment

ThÃªm vÃ o file `.env`:

```env
# Ollama Configuration (Optional - cÃ³ defaults)
OLLAMA_MODEL=qwen2.5:0.5b
OLLAMA_BASE_URL=http://localhost:11434
```

**LÆ°u Ã½:** Náº¿u khÃ´ng set, tool sáº½ dÃ¹ng máº·c Ä‘á»‹nh `qwen2.5:0.5b`

## ğŸ”§ BÆ°á»›c 4: CÃ i Python Dependencies

```powershell
uv pip install llama-index-llms-ollama
```

## âœ… BÆ°á»›c 5: Test RAG Tool

```powershell
.\.venv\Scripts\python.exe test_rag_tool.py
```

## ğŸ“Š So sÃ¡nh Models

| Model | Size | RAM cáº§n | Tá»‘c Ä‘á»™ | Cháº¥t lÆ°á»£ng |
|-------|------|---------|--------|------------|
| qwen2.5:0.5b | 0.5GB | 2GB | Ráº¥t nhanh | Äá»§ dÃ¹ng |
| phi3:mini | 1.7GB | 4GB | Nhanh | Tá»‘t |
| gemma2:2b | 1.6GB | 4GB | Nhanh | Tá»‘t |
| qwen2.5:3b | 4.7GB | 8GB | Vá»«a | Ráº¥t tá»‘t |

## ğŸ¯ Recommended Setup

Cho háº§u háº¿t cÃ¡c trÆ°á»ng há»£p:
```powershell
ollama pull qwen2.5:0.5b
```

Trong `.env`:
```env
OLLAMA_MODEL=qwen2.5:0.5b
```

## ğŸ” Test Ollama trá»±c tiáº¿p

```powershell
# Test chat vá»›i model
ollama run qwen2.5:0.5b

# GÃµ cÃ¢u há»i vÃ  nháº¥n Enter
# GÃµ /bye Ä‘á»ƒ thoÃ¡t
```

## ğŸ› Troubleshooting

### Lá»—i: "Could not connect to Ollama"
**Giáº£i phÃ¡p:** 
```powershell
# Khá»Ÿi Ä‘á»™ng láº¡i Ollama service
ollama serve
```

### Lá»—i: "Model not found"
**Giáº£i phÃ¡p:**
```powershell
# Pull model láº¡i
ollama pull qwen2.5:0.5b
```

### Ollama cháº¡y cháº­m
**Giáº£i phÃ¡p:**
- DÃ¹ng model nhá» hÆ¡n (qwen2.5:0.5b)
- ÄÃ³ng cÃ¡c á»©ng dá»¥ng khÃ¡c
- Kiá»ƒm tra RAM cÃ²n trá»‘ng

## ğŸ“ Sá»­ dá»¥ng RAG Tool

```python
from shared.tools.internal_doc_rag_tool import create_internal_doc_rag_tool

# Tool tá»± Ä‘á»™ng dÃ¹ng Ollama
rag_tool = create_internal_doc_rag_tool()

# Query documents
result = rag_tool._run(query="How many vacation days do employees get?")
print(result)
```

## ğŸŒŸ Æ¯u Ä‘iá»ƒm Ollama

âœ… **Miá»…n phÃ­ 100%** - KhÃ´ng cáº§n API key  
âœ… **Private** - Data khÃ´ng rá»i khá»i mÃ¡y báº¡n  
âœ… **Offline** - Hoáº¡t Ä‘á»™ng khÃ´ng cáº§n internet  
âœ… **Nhanh** - Cháº¡y local, khÃ´ng cÃ³ network latency  
âœ… **Dá»… dÃ¹ng** - Setup trong 5 phÃºt  

## ğŸ”— Links há»¯u Ã­ch

- Ollama Website: https://ollama.com
- Ollama Models Library: https://ollama.com/library
- Ollama GitHub: https://github.com/ollama/ollama
- LlamaIndex Ollama Docs: https://docs.llamaindex.ai/en/stable/examples/llm/ollama/

---

**Created:** November 18, 2025  
**Version:** 1.0.0
